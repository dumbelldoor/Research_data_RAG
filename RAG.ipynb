{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-25T09:48:08.123197Z",
     "start_time": "2024-10-25T09:47:49.072077Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shishirgupta/Car_Price_prediction /Research_data_RAG/.venv/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import adapters.models.auto because of the following error (look up to see its traceback):\ncannot import name 'url_to_filename' from 'huggingface_hub.file_download' (/Users/shishirgupta/Car_Price_prediction /Research_data_RAG/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "File \u001B[0;32m~/Car_Price_prediction /Research_data_RAG/.venv/lib/python3.11/site-packages/transformers/utils/import_utils.py:1586\u001B[0m, in \u001B[0;36m_LazyModule._get_module\u001B[0;34m(self, module_name)\u001B[0m\n\u001B[1;32m   1585\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1586\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmodule_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__name__\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1587\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126\u001B[0m, in \u001B[0;36mimport_module\u001B[0;34m(name, package)\u001B[0m\n\u001B[1;32m    125\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m--> 126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1206\u001B[0m, in \u001B[0;36m_gcd_import\u001B[0;34m(name, package, level)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1178\u001B[0m, in \u001B[0;36m_find_and_load\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1128\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:241\u001B[0m, in \u001B[0;36m_call_with_frames_removed\u001B[0;34m(f, *args, **kwds)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1206\u001B[0m, in \u001B[0;36m_gcd_import\u001B[0;34m(name, package, level)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1178\u001B[0m, in \u001B[0;36m_find_and_load\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1149\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:690\u001B[0m, in \u001B[0;36m_load_unlocked\u001B[0;34m(spec)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap_external>:940\u001B[0m, in \u001B[0;36mexec_module\u001B[0;34m(self, module)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:241\u001B[0m, in \u001B[0;36m_call_with_frames_removed\u001B[0;34m(f, *args, **kwds)\u001B[0m\n",
      "File \u001B[0;32m~/Car_Price_prediction /Research_data_RAG/.venv/lib/python3.11/site-packages/adapters/models/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01malbert\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmixin_albert\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AlbertModelAdaptersMixin\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbart\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmixin_bart\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      3\u001B[0m     BartDecoderAdaptersMixin,\n\u001B[1;32m      4\u001B[0m     BartDecoderWrapperAdaptersMixin,\n\u001B[1;32m      5\u001B[0m     BartEncoderAdaptersMixin,\n\u001B[1;32m      6\u001B[0m     BartModelAdaptersMixin,\n\u001B[1;32m      7\u001B[0m )\n",
      "File \u001B[0;32m~/Car_Price_prediction /Research_data_RAG/.venv/lib/python3.11/site-packages/adapters/models/albert/mixin_albert.py:6\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcomposition\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m adjust_tensors_for_parallel_\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmethods\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbottleneck\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BottleneckLayer\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmethods\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlora\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LoRALinear\n",
      "File \u001B[0;32m~/Car_Price_prediction /Research_data_RAG/.venv/lib/python3.11/site-packages/adapters/methods/bottleneck.py:16\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcomposition\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      7\u001B[0m     AdapterCompositionBlock,\n\u001B[1;32m      8\u001B[0m     Average,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     14\u001B[0m     adjust_tensors_for_parallel,\n\u001B[1;32m     15\u001B[0m )\n\u001B[0;32m---> 16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconfiguration\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BnConfig\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcontext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ForwardContext\n",
      "File \u001B[0;32m~/Car_Price_prediction /Research_data_RAG/.venv/lib/python3.11/site-packages/adapters/configuration/__init__.py:2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# flake8: noqa\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01madapter_config\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01madapter_fusion_config\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[0;32m~/Car_Price_prediction /Research_data_RAG/.venv/lib/python3.11/site-packages/adapters/configuration/adapter_config.py:6\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m List, Literal, Optional, Union\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m resolve_adapter_config\n\u001B[1;32m      9\u001B[0m logger \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mgetLogger(\u001B[38;5;18m__name__\u001B[39m)\n",
      "File \u001B[0;32m~/Car_Price_prediction /Research_data_RAG/.venv/lib/python3.11/site-packages/adapters/utils.py:28\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mhuggingface_hub\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HfApi, HfFolder, snapshot_download\n\u001B[0;32m---> 28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mhuggingface_hub\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfile_download\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m http_get, url_to_filename\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mhuggingface_hub\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     30\u001B[0m     EntryNotFoundError,\n\u001B[1;32m     31\u001B[0m     RepositoryNotFoundError,\n\u001B[1;32m     32\u001B[0m     RevisionNotFoundError,\n\u001B[1;32m     33\u001B[0m     hf_raise_for_status,\n\u001B[1;32m     34\u001B[0m )\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'url_to_filename' from 'huggingface_hub.file_download' (/Users/shishirgupta/Car_Price_prediction /Research_data_RAG/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 22\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m \u001B[38;5;66;03m# Numpy array\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoTokenizer\n\u001B[0;32m---> 22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01madapters\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoAdapterModel  \n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvectorstores\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FAISS \u001B[38;5;66;03m#Langchain Vector store \u001B[39;00m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoTokenizer, AutoModelForCausalLM \u001B[38;5;66;03m#LLM (Llama2)\u001B[39;00m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1231\u001B[0m, in \u001B[0;36m_handle_fromlist\u001B[0;34m(module, fromlist, import_, recursive)\u001B[0m\n",
      "File \u001B[0;32m~/Car_Price_prediction /Research_data_RAG/.venv/lib/python3.11/site-packages/transformers/utils/import_utils.py:1576\u001B[0m, in \u001B[0;36m_LazyModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1574\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_module(name)\n\u001B[1;32m   1575\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_class_to_module\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m-> 1576\u001B[0m     module \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_class_to_module\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1577\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(module, name)\n\u001B[1;32m   1578\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Car_Price_prediction /Research_data_RAG/.venv/lib/python3.11/site-packages/transformers/utils/import_utils.py:1588\u001B[0m, in \u001B[0;36m_LazyModule._get_module\u001B[0;34m(self, module_name)\u001B[0m\n\u001B[1;32m   1586\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m importlib\u001B[38;5;241m.\u001B[39mimport_module(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m module_name, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[1;32m   1587\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m-> 1588\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m   1589\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to import \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodule_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m because of the following error (look up to see its\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1590\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m traceback):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1591\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Failed to import adapters.models.auto because of the following error (look up to see its traceback):\ncannot import name 'url_to_filename' from 'huggingface_hub.file_download' (/Users/shishirgupta/Car_Price_prediction /Research_data_RAG/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'\n",
    "import torch\n",
    "import json\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from pprint import pprint #Pretty Print to print better json\n",
    "from PyPDF2 import PdfReader\n",
    "from openai import OpenAI\n",
    "import langchain_community\n",
    "from langchain.document_loaders import PyPDFLoader \n",
    "from langchain.text_splitter import RecursiveJsonSplitter # Recursive Json splitter to spilit data.\n",
    "from langchain_community.document_loaders import UnstructuredURLLoader #URL loaders \n",
    "from langchain_community.document_loaders import AsyncHtmlLoader #AsyncHTML Loader to load HTML into data.\n",
    "from langchain.text_splitter import CharacterTextSplitter # Character Text Spilitter to split text in chunks.\n",
    "from langchain_community.document_loaders import JSONLoader #Load Json files into the code using JSONLoadder.\n",
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings # Embeddings from Hugging face Hub\n",
    "from sentence_transformers import SentenceTransformer # Scentence Transformers to transfromation model.\n",
    "import faiss # Facebook research model\n",
    "import numpy as np # Numpy array\n",
    "from transformers import AutoTokenizer\n",
    "from adapters import AutoAdapterModel  \n",
    "from langchain.vectorstores import FAISS #Langchain Vector store \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM #LLM (Llama2)\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the Json file using json loader.\n",
    "file_path = './final_data.json'\n",
    "data = json.loads(Path(file_path).read_text())\n",
    "\n",
    "\n",
    "\n",
    "texts = []\n",
    "for paper in data:\n",
    "    text = f\"{paper['Title']} {paper.get('Abstract', '')} {paper['Authors']} {paper.get('Author(s) ID','')}{paper.get('References', '')}\"\n",
    "    texts.append(text)\n",
    "\n",
    "\n",
    "\n",
    "texts = texts[:100]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_name = \"allenai/specter2_base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "\n",
    "# model.load_adapter(\"allenai/specter2\", source=\"hf\", load_as=\"specter2\", set_active=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model = SentenceTransformer(\"allenai-specter2\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"allenai/specter2_base\")\n",
    "# model = AutoAdapterModel.from_pretrained(\"allenai/specter2_base\")\n",
    "\n",
    "\n",
    "# Load model directly\n",
    "\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n",
    "\n",
    "\n",
    "inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "\n",
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Running on GPU MODE\")\n",
    "    inputs = {key: tensor.cuda() for key, tensor in inputs.items()}\n",
    "    model.cuda()\n",
    "else:\n",
    "    print(\"Running on CPU\")\n",
    "\n",
    "# Generate the model's output\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Retrieve embeddings from the last hidden state\n",
    "embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()  # Convert to numpy\n",
    "print(\"This part is also working\")\n",
    "\n",
    "# Add to FAISS index\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "embeddings = embeddings.astype('float32')\n",
    "index.add(embeddings)\n",
    "\n",
    "\n",
    "\n",
    "print(\"FAISS index built successfully with new embeddings!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def query_index(query, index, data, model, tokenizer):\n",
    "    # Tokenize and encode the query\n",
    "    query_input = tokenizer(query, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "\n",
    "    # Move to GPU if available\n",
    "    if torch.cuda.is_available():\n",
    "        query_input = {key: tensor.cuda() for key, tensor in query_input.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        query_output = model(**query_input)\n",
    "\n",
    "    query_embedding = query_output.last_hidden_state[:, 0, :].cpu().numpy().astype('float32')\n",
    "\n",
    "    # Perform similarity search\n",
    "    distances, indices = index.search(query_embedding, 5)  # Retrieve top 5 results\n",
    "\n",
    "    # Display results\n",
    "    print(\"Query Results:\")\n",
    "    print(\"Indices of matching documents:\", indices[0])\n",
    "    for dist, idx in zip(distances[0], indices[0]):\n",
    "        \n",
    "        paper = data[idx]\n",
    "        print(f\"Title: {paper['Title']}\")\n",
    "        print(f\"Abstract: {paper.get('Abstract', '')}\")\n",
    "        print(f\"Authors: {paper['Authors']}\")\n",
    "        print(f\"Distance: {dist}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "user_query = input(\"Enter your query: \")\n",
    "query_index(user_query, index, data, model, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9112af7da2ea5611"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
